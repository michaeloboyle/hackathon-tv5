use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use std::collections::HashMap;
use std::sync::Arc;
use tracing::{debug, info, instrument};
use uuid::Uuid;

pub mod filters;
pub mod keyword;
pub mod vector;

pub use filters::SearchFilters;
pub use keyword::KeywordSearch;
pub use vector::VectorSearch;

use crate::cache::RedisCache;
use crate::config::DiscoveryConfig;
use crate::intent::{IntentParser, ParsedIntent};

/// Hybrid search service orchestrator
pub struct HybridSearchService {
    config: Arc<DiscoveryConfig>,
    intent_parser: Arc<IntentParser>,
    vector_search: Arc<vector::VectorSearch>,
    keyword_search: Arc<keyword::KeywordSearch>,
    db_pool: sqlx::PgPool,
    cache: Arc<RedisCache>,
}

/// Search request
#[derive(Debug, Clone, Serialize)]
pub struct SearchRequest {
    pub query: String,
    pub filters: Option<SearchFilters>,
    pub page: u32,
    pub page_size: u32,
    pub user_id: Option<Uuid>,
}

/// Search response
#[derive(Debug, Serialize, Deserialize)]
pub struct SearchResponse {
    pub results: Vec<SearchResult>,
    pub total_count: usize,
    pub page: u32,
    pub page_size: u32,
    pub query_parsed: ParsedIntent,
    pub search_time_ms: u64,
}

/// Individual search result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SearchResult {
    pub content: ContentSummary,
    pub relevance_score: f32,
    pub match_reasons: Vec<String>,
    pub vector_similarity: Option<f32>,
    pub graph_score: Option<f32>,
    pub keyword_score: Option<f32>,
}

/// Content summary for search results
#[derive(Debug, Clone, Serialize, Deserialize, sqlx::FromRow)]
pub struct ContentSummary {
    pub id: Uuid,
    pub title: String,
    pub overview: String,
    pub release_year: i32,
    pub genres: Vec<String>,
    pub platforms: Vec<String>,
    pub popularity_score: f32,
}

impl HybridSearchService {
    /// Create new hybrid search service
    pub fn new(
        config: Arc<DiscoveryConfig>,
        intent_parser: Arc<IntentParser>,
        vector_search: Arc<vector::VectorSearch>,
        keyword_search: Arc<keyword::KeywordSearch>,
        db_pool: sqlx::PgPool,
        cache: Arc<RedisCache>,
    ) -> Self {
        Self {
            config,
            intent_parser,
            vector_search,
            keyword_search,
            db_pool,
            cache,
        }
    }

    /// Execute hybrid search with caching
    #[instrument(skip(self), fields(query = %request.query, page = %request.page))]
    pub async fn search(&self, request: SearchRequest) -> anyhow::Result<SearchResponse> {
        let start_time = std::time::Instant::now();

        // Generate cache key from request
        let cache_key = self.generate_cache_key(&request);

        // Check cache first
        if let Ok(Some(cached_response)) = self.cache.get::<SearchResponse>(&cache_key).await {
            let cache_time_ms = start_time.elapsed().as_millis() as u64;
            info!(
                cache_key = %cache_key,
                cache_time_ms = %cache_time_ms,
                "Cache hit - returning cached search results"
            );
            return Ok(cached_response);
        }

        debug!(cache_key = %cache_key, "Cache miss - executing full search");

        // Execute full search pipeline
        let response = self.execute_search(&request).await?;

        // Cache results with 30-minute TTL
        if let Err(e) = self.cache.set(&cache_key, &response, 1800).await {
            // Log cache write error but don't fail the request
            debug!(error = %e, cache_key = %cache_key, "Failed to cache search results");
        } else {
            debug!(cache_key = %cache_key, ttl = 1800, "Cached search results");
        }

        Ok(response)
    }

    /// Execute the full search pipeline (without caching)
    #[instrument(skip(self), fields(query = %request.query))]
    async fn execute_search(&self, request: &SearchRequest) -> anyhow::Result<SearchResponse> {
        let start_time = std::time::Instant::now();

        // Phase 1: Parse intent
        let intent = self.intent_parser.parse(&request.query).await?;

        // Phase 2: Execute parallel search strategies
        let (vector_results, keyword_results) = tokio::join!(
            self.vector_search.search(&request.query, request.filters.clone()),
            self.keyword_search.search(&request.query, request.filters.clone())
        );

        // Phase 3: Merge results using Reciprocal Rank Fusion
        let merged_results = self.reciprocal_rank_fusion(
            vector_results?,
            keyword_results?,
            self.config.search.rrf_k,
        );

        // Phase 4: Apply personalization if user_id provided
        let ranked_results = if let Some(_user_id) = request.user_id {
            // TODO: Apply user preference scoring
            merged_results
        } else {
            merged_results
        };

        // Phase 5: Paginate
        let total_count = ranked_results.len();
        let start = ((request.page - 1) * request.page_size) as usize;
        let end = std::cmp::min(start + request.page_size as usize, total_count);
        let page_results = ranked_results[start..end].to_vec();

        let search_time_ms = start_time.elapsed().as_millis() as u64;

        info!(
            search_time_ms = %search_time_ms,
            total_results = %total_count,
            "Completed full search execution"
        );

        Ok(SearchResponse {
            results: page_results,
            total_count,
            page: request.page,
            page_size: request.page_size,
            query_parsed: intent,
            search_time_ms,
        })
    }

    /// Vector-only search
    pub async fn vector_search(
        &self,
        query: &str,
        filters: Option<SearchFilters>,
        _limit: Option<usize>,
    ) -> anyhow::Result<Vec<SearchResult>> {
        self.vector_search.search(query, filters).await
    }

    /// Keyword-only search
    pub async fn keyword_search(
        &self,
        query: &str,
        filters: Option<SearchFilters>,
        _limit: Option<usize>,
    ) -> anyhow::Result<Vec<SearchResult>> {
        self.keyword_search.search(query, filters).await
    }

    /// Get content by ID
    pub async fn get_content_by_id(&self, id: Uuid) -> anyhow::Result<Option<ContentSummary>> {
        let result = sqlx::query_as::<_, ContentSummary>(
            r#"
            SELECT
                id,
                title,
                overview,
                release_year,
                genres,
                ARRAY[]::text[] as "platforms!: Vec<String>",
                popularity_score
            FROM content
            WHERE id = $1
            "#
        )
        .bind(id)
        .fetch_optional(&self.db_pool)
        .await?;

        Ok(result)
    }

    /// Reciprocal Rank Fusion (RRF) algorithm
    /// Merges results from multiple search strategies
    fn reciprocal_rank_fusion(
        &self,
        vector_results: Vec<SearchResult>,
        keyword_results: Vec<SearchResult>,
        k: f32,
    ) -> Vec<SearchResult> {
        let mut scores: HashMap<Uuid, (f32, SearchResult)> = HashMap::new();

        // Process vector results
        for (rank, result) in vector_results.iter().enumerate() {
            let rrf_score = self.config.search.weights.vector / (k + (rank + 1) as f32);
            scores
                .entry(result.content.id)
                .and_modify(|(score, _)| *score += rrf_score)
                .or_insert((rrf_score, result.clone()));
        }

        // Process keyword results
        for (rank, result) in keyword_results.iter().enumerate() {
            let rrf_score = self.config.search.weights.keyword / (k + (rank + 1) as f32);
            scores
                .entry(result.content.id)
                .and_modify(|(score, _)| *score += rrf_score)
                .or_insert((rrf_score, result.clone()));
        }

        // Sort by combined score
        let mut merged: Vec<(f32, SearchResult)> = scores
            .into_iter()
            .map(|(_, (score, mut result))| {
                result.relevance_score = score;
                (score, result)
            })
            .collect();

        merged.sort_by(|a, b| b.0.partial_cmp(&a.0).unwrap_or(std::cmp::Ordering::Equal));

        merged.into_iter().map(|(_, result)| result).collect()
    }

    /// Generate cache key from search request using SHA256 hash
    ///
    /// The cache key includes:
    /// - Query string
    /// - Filters (genres, platforms, year range, rating range)
    /// - Pagination (page, page_size)
    /// - User ID for personalized results
    ///
    /// # Arguments
    /// * `request` - Search request to generate key for
    ///
    /// # Returns
    /// Cache key string in format: "search:{sha256_hash}"
    #[instrument(skip(self, request), fields(query = %request.query))]
    fn generate_cache_key(&self, request: &SearchRequest) -> String {
        // Serialize request to JSON for consistent hashing
        let json = serde_json::to_string(request)
            .expect("SearchRequest serialization should never fail");

        // Generate SHA256 hash
        let mut hasher = Sha256::new();
        hasher.update(json.as_bytes());
        let hash = hasher.finalize();
        let hash_hex = hex::encode(hash);

        // Create cache key with search prefix
        let key = format!("search:{}", hash_hex);
        debug!(cache_key = %key, "Generated cache key");

        key
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_reciprocal_rank_fusion() {
        // Create mock results
        let content1 = ContentSummary {
            id: Uuid::new_v4(),
            title: "Movie 1".to_string(),
            overview: "Description".to_string(),
            release_year: 2020,
            genres: vec!["action".to_string()],
            platforms: vec![],
            popularity_score: 0.8,
        };

        let content2 = ContentSummary {
            id: Uuid::new_v4(),
            title: "Movie 2".to_string(),
            overview: "Description".to_string(),
            release_year: 2021,
            genres: vec!["drama".to_string()],
            platforms: vec![],
            popularity_score: 0.7,
        };

        let vector_results = vec![
            SearchResult {
                content: content1.clone(),
                relevance_score: 0.9,
                match_reasons: vec![],
                vector_similarity: Some(0.9),
                graph_score: None,
                keyword_score: None,
            },
            SearchResult {
                content: content2.clone(),
                relevance_score: 0.8,
                match_reasons: vec![],
                vector_similarity: Some(0.8),
                graph_score: None,
                keyword_score: None,
            },
        ];

        let keyword_results = vec![SearchResult {
            content: content2.clone(),
            relevance_score: 0.85,
            match_reasons: vec![],
            vector_similarity: None,
            graph_score: None,
            keyword_score: Some(0.85),
        }];

        // Mock config
        let config = Arc::new(DiscoveryConfig::default());

        // Mock cache config
        let cache_config = Arc::new(crate::config::CacheConfig {
            redis_url: "redis://localhost:6379".to_string(),
            search_ttl_sec: 1800,
            embedding_ttl_sec: 3600,
            intent_ttl_sec: 600,
        });

        // Skip test if Redis is not available
        let cache = match RedisCache::new(cache_config).await {
            Ok(c) => Arc::new(c),
            Err(_) => {
                eprintln!("Skipping test: Redis not available");
                return;
            }
        };

        // Create mock database pool (would fail if postgres not available)
        let db_pool = match sqlx::PgPool::connect("postgresql://localhost/test").await {
            Ok(pool) => pool,
            Err(_) => {
                eprintln!("Skipping test: PostgreSQL not available");
                return;
            }
        };

        let service = HybridSearchService {
            config,
            intent_parser: Arc::new(IntentParser::new(String::new(), String::new())),
            vector_search: Arc::new(vector::VectorSearch::new(
                String::new(),
                String::new(),
                768,
            )),
            keyword_search: Arc::new(keyword::KeywordSearch::new(String::new())),
            db_pool,
            cache,
        };

        let merged = service.reciprocal_rank_fusion(vector_results, keyword_results, 60.0);

        // content2 should rank higher (appears in both results)
        assert_eq!(merged[0].content.id, content2.id);
    }

    #[test]
    fn test_cache_key_generation() {
        // Test that cache key generation is deterministic
        let request1 = SearchRequest {
            query: "test query".to_string(),
            filters: Some(SearchFilters {
                genres: vec!["action".to_string()],
                platforms: vec!["netflix".to_string()],
                year_range: Some((2020, 2024)),
                rating_range: None,
            }),
            page: 1,
            page_size: 20,
            user_id: Some(Uuid::nil()), // Use nil UUID for deterministic testing
        };

        let request2 = request1.clone();

        // Serialize both requests
        let json1 = serde_json::to_string(&request1).unwrap();
        let json2 = serde_json::to_string(&request2).unwrap();

        // Generate hashes
        use sha2::Digest;
        let hash1 = hex::encode(Sha256::digest(json1.as_bytes()));
        let hash2 = hex::encode(Sha256::digest(json2.as_bytes()));

        // Same request should produce same hash
        assert_eq!(hash1, hash2, "Cache keys should be deterministic");

        // Verify key format
        let key = format!("search:{}", hash1);
        assert!(key.starts_with("search:"));
        assert_eq!(key.len(), "search:".len() + 64); // SHA256 = 64 hex chars
    }
}
